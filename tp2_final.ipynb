{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP2: Premier réseau de neurone avec PyTorch\n",
    "=============\n",
    "\n",
    "Introduction au sujet\n",
    "-----\n",
    "\n",
    "L'objectif de ce sujet est de mettre en place un premier réseau de neurone pour classer des fleurs de la base IRIS.\n",
    "\n",
    "Le code est à écrire en python3 à la suite des questions dans ce fichier. Vous appuierez soit sur le bouton *run cell*, soit sur les touches *Ctrl-Entrée*, à l’intérieur de la zone de saisie, pour lancer l'exécution de vos commandes. Si la commande est en cours d’exécution une étoile apparaît à côté de la zone de saisie de la commande : In [\\*]. Une fois le calcul achevé, l'étoile est remplacée par le numéro du run permettant de retrouver par la suite dans quel ordre ont été lancés chaque bloc.\n",
    "\n",
    "N'hésitez pas à regarder régulièrement la documentation de ces librairies, des exemples d'utilisation accompagnent généralement l'explication de chaque fonction.\n",
    "\n",
    "Langage utilisé:\n",
    "- Python 3: https://docs.python.org/3/\n",
    "\n",
    "Librairie de math:\n",
    "- Numpy: https://docs.scipy.org/doc/numpy/reference/\n",
    "- Scipy: https://docs.scipy.org/doc/scipy/reference/\n",
    "\n",
    "Librairie d'affichage de données:\n",
    "- Matplotilb: https://matplotlib.org/contents.html\n",
    "\n",
    "Librairie Pytorch:\n",
    "- PyTorch: https: https://pytorch.org/docs/stable/\n",
    "\n",
    "Commencez par importer les librairies nécessaires au TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Import numpy et matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import de scikit-learn\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch: Premier réseau sur la base IRIS\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans ce TP étudier la base *IRIS* et tester un réseau entièrement connecté dessus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencez par charger la base *IRIS* avec sckit-learn. Vous mettrez les descripteurs des fleurs dans une variable `X` et les labels dans une variable `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sklearn.datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez que le code suivant affiche bien des *True*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(X.shape == (150,4))\n",
    "print(y.shape == (150,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparez l'ensemble d'apprentissage en deux en utilisant la fonction train_test_split de sckit-learn. Un ensemble d'apprentissage *train* et un ensemble de *test*. Vous prendrez 1/3 des images pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,y_train,y_test=sk.model_selection.train_test_split(X,y,test_size = 1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez les dimensions des données produites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 -> (100, 4) (100,)\n",
      "50.0 -> (50, 4) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(2*len(X)/3,'->',train.shape,y_train.shape)\n",
    "print(len(X)/3,'->',test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un classifieur *iris_classifier* correspondant à un réseau entièrement connecté de 3 couches cachées de tailles [10,20,10]. Après chaque couche cachée, vous appliquerez une fonction d'activation de type ReLU. N'oubliez pas la dernière couche de sortie. Vous utiliseriez `torch.nn.Sequential` pour faire cette question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_classifier = torch.nn.Sequential(\n",
    "    nn.Linear(X.shape[1],10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10,20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un objet `iter_train` permettant de parcourir la base de donnée d'entrainement avec des batchs aléatoires de taille 32. Vous utiliserez les classes `TensorDataset` et `DataLoader` pour cette question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(torch.FloatTensor(train), torch.FloatTensor(y_train))\n",
    "\n",
    "iter_train = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez un objet `iter_test` permettant de parcourir la base de donnée de test avec des batchs de taille 10 concervant l'ordre d'origine des exemples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = torch.utils.data.TensorDataset(torch.FloatTensor(test), torch.FloatTensor(y_test))\n",
    "iter_test = torch.utils.data.DataLoader(test_ds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez une optimiser de type gradient stochastique initialisé avec un taux d'apprentissage de $10^{-2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(iris_classifier.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissze un critère de type cross-entropie qui sera utilisé comme fonction de coût optimisant notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuez 100 époques d'apprentissage du classifieur `iris_classifier` avec les données de `iter_train`. Vous utiliserez pour celà un algorithme de gradient stochastique avec une fonction de coût de type cross-entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0 / 100 0.1233542263507843\n",
      "loss :  10 / 100 0.0008796900510787964\n",
      "loss :  20 / 100 0.024071089923381805\n",
      "loss :  30 / 100 0.00015171038103289902\n",
      "loss :  40 / 100 0.0033867498859763145\n",
      "loss :  50 / 100 0.000732307496946305\n",
      "loss :  60 / 100 0.012136667035520077\n",
      "loss :  70 / 100 0.0014039475936442614\n",
      "loss :  80 / 100 0.007681097835302353\n",
      "loss :  90 / 100 0.008869434706866741\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    iris_classifier.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in iter_train:\n",
    "        outputs = iris_classifier(x)\n",
    "        loss = loss_func(outputs, y.type(torch.LongTensor))\n",
    "        loss.backward() # calcul des gradients\n",
    "        optimizer.step() # mise a jours des poids\n",
    "        optimizer.zero_grad() #mise a 0 des gradients\n",
    "        \n",
    "    if i%10==0:\n",
    "        print(\"loss : \", i,\"/\",100,loss.item())\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluez les performances du réseau appris à la  question précédente sur les données de test de `iter_test`. Pour faire  cette  question vous calculerez dans une boucle le nombre de fois que l'algorithme s'est trompé sur la base de test. Pensez à désactiver le calcul des gradients sur la base de test afin de pas perturbé avec des données de tests de nouveaux apprentissages de votre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total, correct = 0, 0\n",
    "    for x, y in iter_test:\n",
    "        outputs = iris_classifier(x)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "    print(correct/total)\n",
    "        \n",
    "iris_classifier.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relancez les lignes effectuant l'apprentissage et l'évaluation. Comment évolue les performances d'apprentissage ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## -> plus on relance l'entrainement plus les resultats obtenus sont bons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez tensorboard pour visualiser le graphe correspondant à votre réseau et les différentes courbes correspondant à l'apprentissage de ce dernier.\n",
    "\n",
    "Vous pouvez pour cela:\n",
    "- Soit installez le plugin tensorboard pour jupyter: pip3 install --user jupyter-tensorboard\n",
    "\n",
    "Puis vous suivez les informations d'écrit sur la page: https://github.com/lspvic/jupyter_tensorboard\n",
    "- Soit lancer dans un terminal: tensorboard --logdir=.\n",
    "\n",
    "Puis vous vous connectez à http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch: Définition d'un réseau couche par couche\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans cette partie redéfinir le réseau couche par couche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissez une classe `Net` définissant le réseau précédant sans utiliser de `torch.nn.Sequential`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Net(nn.Module):\n",
    "    def __init__(self,shape):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(shape,10)\n",
    "        self.fc2 = nn.Linear(10,20)\n",
    "        self.fc3 = nn.Linear(20,10)\n",
    "        self.fc4 = nn.Linear(10,3)\n",
    "    def forward(self, x):\n",
    "        out = nn.functional.relu(self.fc1(x))\n",
    "        out = nn.functional.relu(self.fc2(out))\n",
    "        out = nn.functional.relu(self.fc3(out))\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "net_classifier = Net(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprenez ce réseau sur les données d'apprentissage de la base IRIS avec un algorithme de descende de gradient de type AdaGrad dont le taux d'apprentissage est de $10^{-2}$ avec une fonction de coût de type cross-entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /100, loss= 0.05393264815211296\n",
      "10 /100, loss= 0.027893440797924995\n",
      "20 /100, loss= 0.10496604442596436\n",
      "30 /100, loss= 0.017542323097586632\n",
      "40 /100, loss= 0.006252109073102474\n",
      "50 /100, loss= 0.09634821861982346\n",
      "60 /100, loss= 0.012993291951715946\n",
      "70 /100, loss= 0.003913518041372299\n",
      "80 /100, loss= 0.14153525233268738\n",
      "90 /100, loss= 0.012239650823175907\n",
      "100 /100, loss= 0.011983118951320648\n"
     ]
    }
   ],
   "source": [
    "opti = torch.optim.Adagrad(net_classifier.parameters(),lr=0.01)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_classifier.train()\n",
    "for epoch in range (101):\n",
    "    for xb,yb in iter_train:\n",
    "        output = net_classifier(xb)\n",
    "        loss = loss_func(output,yb.type(torch.LongTensor))\n",
    "        \n",
    "        loss.backward() # calcul des gradients\n",
    "        opti.step() # mise a jours des poids\n",
    "        opti.zero_grad() #mise a 0 des gradients\n",
    "        \n",
    "    if (epoch%10==0):\n",
    "        print(epoch,\"/100, loss=\",loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez le réseau que vous venez d'apprendre sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test:  98.0 %\n"
     ]
    }
   ],
   "source": [
    "net_classifier.eval()\n",
    "correct=0\n",
    "with torch.no_grad():\n",
    "    for data,target in iter_test:\n",
    "        output = net_classifier(data)\n",
    "        pred = output.argmax(dim = 1, keepdim=True)\n",
    "        correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    print(\"Accuracy sur test: \",100*correct/len(iter_test.dataset),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardez le modèle que vous venez d'apprendre dans un fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_classifier.state_dict(), \"./save_net\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez le réseau que vous venez de sauvegarder et vérifier que les performances sur la base de test n'ont pas changé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur test:  98.0 %\n"
     ]
    }
   ],
   "source": [
    "model = Net(4)\n",
    "model.load_state_dict(torch.load(\"./save_net\"))\n",
    "model.eval()\n",
    "correct=0\n",
    "with torch.no_grad():\n",
    "    for data,target in iter_test:\n",
    "        output = net_classifier(data)\n",
    "        pred = output.argmax(dim = 1, keepdim=True)\n",
    "        correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    print(\"Accuracy sur test: \",100*correct/len(iter_test.dataset),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparez les graphes des deux méthodes dans tensorboard. Retrouvez-vous les même éléments ? Qu'est ce qui diffère entre les deux versions ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec un SVM \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la librairie sckit-learn et le cours de Machine learning du premier semestre, trouver les performances du meilleur SVM sur ces données et comparer les performances avec celle du réseau de neurone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
